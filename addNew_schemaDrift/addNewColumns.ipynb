{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0c9d6a0c-a2a2-4abf-a18e-baa38bca0803",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Libraries management\n",
    "from pyspark import pipelines as pl\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "volume_path=\"/Volumes/workspace/sd_schema/datastore/customer_*.json\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "72c9c501-6368-43af-8260-eebbf59d6ebc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#bronze layer table: cust_bronze_sd\n",
    "pl.create_streaming_table(\"cust_bronze_sd_addNew\")\n",
    "\n",
    "# Ingest the raw data into the bronze table using append flow\n",
    "@pl.append_flow(\n",
    "  target = \"cust_bronze_sd_addNew\", #object name\n",
    "  name = \"cust_bronze_sd_addNew_ingest_flow\" #flow name\n",
    ")\n",
    "def cust_bronze_sd_addNew_ingest_flow():\n",
    "  df = (\n",
    "    \n",
    "\n",
    "      spark.readStream\n",
    "          .format(\"cloudFiles\")\n",
    "          .option(\"cloudFiles.format\", \"json\")\n",
    "          .option(\"cloudFiles.inferColumnTypes\", \"true\") #auto scan schema \n",
    "          #.option(\"cloudFiles.schemaEvolutionMode\", \"failOnNewColumns\") # schema customer_data_1.json is different than customer_data_2.json so it fails with  [UNKNOWN_FIELD_EXCEPTION.NEW_FIELDS_IN_RECORD_WITH_FILE_PATH] excetion and stops processing\n",
    "          .option(\"cloudFiles.schemaEvolutionMode\", \"addNewColumns\")\n",
    "          .load(f\"{volume_path}\")\n",
    "  )\n",
    "  return df.withColumn(\"ingestion_datetime\", current_timestamp())\\\n",
    "           .withColumn(\"source_filename\", col(\"_metadata.file_path\")) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "92339f83-6916-4ada-90a0-6ca34ec6593d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pl.create_streaming_table(\n",
    "    name=\"cust_silver_sd_addNew\",\n",
    "    expect_all_or_drop={\n",
    "        \"valid_id\": \"CustomerID IS NOT NULL\"\n",
    "    }\n",
    ")\n",
    "\n",
    "@pl.append_flow(\n",
    "    target=\"cust_silver_sd_addNew\",\n",
    "    name=\"cust_silver_sd_addNew_flow\"\n",
    ")\n",
    "def cust_silver_sd_addNew_flow():\n",
    "    df = spark.readStream.table(\"cust_bronze_sd_addNew\")\n",
    "    \n",
    "    # Apply data type conversions for specific columns\n",
    "    # These conversions will only apply if the columns exist\n",
    "    \n",
    "    # Convert SignupDate from String to Date (from customer_data_1.json)\n",
    "    if \"SignupDate\" in df.columns:\n",
    "        df = df.withColumn(\"SignupDate\", col(\"SignupDate\").cast(DateType()))\n",
    "    \n",
    "    # Convert Age to Integer (from customer_data_2.json)\n",
    "    if \"Age\" in df.columns:\n",
    "        df = df.withColumn(\"Age\", col(\"Age\").cast(IntegerType()))\n",
    "    \n",
    "    # Convert CreditScore to Integer (from customer_data_4.json)\n",
    "    if \"CreditScore\" in df.columns:\n",
    "        df = df.withColumn(\"CreditScore\", col(\"CreditScore\").cast(IntegerType()))\n",
    "    \n",
    "    # Additional transformations can be added here:\n",
    "    # - Data quality checks\n",
    "    # - Business logic\n",
    "    # - Derived columns\n",
    "    # - Data cleansing\n",
    "    \n",
    "    return df\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "addNewColumns",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
